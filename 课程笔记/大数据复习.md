### 大数据复习

#### 概念题：

1. Hadoop概念：

   ==概念==：**Hadoop是一个能够对大量数据进行分布式处理的软件框架**，是Apache基金会旗下的一个开源分布式计算平台，为用户提供系统底层细节透明的分布式基础架构。基于Java开发，具有很好的跨平台特性，可以部署在廉价的计算机就集群中。
   由分布式计算系统MapReduce，分布式文件管理系统HDFS和分布式资源调度管理框架yarn构成

   ==组成（核心）==：Hadoop分布式文件系统（Hadoop Distributed File System——HDFS）、

   MapReduce。

   ==特性==：高可靠性、高效性、高可扩展性、高容错性、成本低、运行在Linux操作系统上、支持多种编程语言。

2. MapReduce概念：
   ==概念==：**MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算**。它将复杂的、运行于大规模集群上的并行计算过程高度抽象为两个函数——Map和Reduce。通常来说，**MapReduce的核心思想就是“分而治之”**。

3. HDFS相关概念：

   1. HDFS：分布式文件系统是一种通过网络实现文件在多台主机上进行分布式存储的文件系统。一般采用Client/Server模式。

   2. 块：传统文件系统中，为了提高磁盘读写效率，一般以数据块为单位，而不是以字节为单位，这是因为在读取数据时有一个寻道的过程，通过转动盘片和移动磁头的位置，找到数据在机械式硬盘中的存储位置，才能进行读写，剩下的顺序读取效率是非常高的。HDFS同样采用了块的概念，目的是最小化寻址开销。HDFS寻址开销不仅包括磁盘寻道开销，还包括数据块定位开销。

      好处：

      - 支持大规模文件存储
      - 简化系统设计
      - 适合数据备份

   3. 名称节点：下文

   4. 数据节点：分布式文件系统的工作节点，负责数据的存储和读取，会根据客户端或者名称节点的调度来进行数据的存储和检索，并向名称节点定期发送自己所存储的块的列表信息。

   5. 第二名称节点：定期从NameNode中复制元数据并对其合并，生成新的检查点。
      作用：

      - 有效解决了EditLog逐渐变大带来的问题。减小了EditLog文件大小，缩短名称节点重启时间。
      - 作为名称节点的检查点，保存名称节点中的元数据信息。

4. NameNode（名称节点）概念：

   ==概念==：在HDFS中，**名称节点负责管理分布式文件系统的命名空间（Namespace）**，保存了两个数据结构，FsImage和EditLog。FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据，操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作。**名称节点记录了每个文件中各个块所在的数据节点的位置信息**，但是并不持久化保存这些信息，而是在系统每次启动使扫描所有数据节点并重构，得到这些信息。

5. NameNode启动时做哪些操作
   ==首次启动==：

   1. 格式化NameNode，生成fsimage镜像文件
   2. 启动NameNode
      - 读取fsimage镜像文件，将文件内容加载进内存。
      - 等待DataNode注册和block report。
   3. 启动DataNode：
      - 首先向NameNode进行注册
      - 发送block report
      - 检查fsimage中的block report是否和block report中的数量一直
   4. 对文件系统进行操作：
      - 此时创建目录、上传文件等信息会被记录在edits中

   ==非首次启动==：

   1. 将FsImage的内容加载到内存中，然后执行EditLog文件中的各种操作，使内存中的元数据保持最新。
   2. 创建一个新的FsImage文件和一个空的EditLog文件。
   3. 名称节点启动成功并进入正常运行状态后，HDFS的所有更新操作都会被写入EditLog，而不是直接写入FsImage。

6. HDFS组成：

   1. Client（客户端）：提供与HDFS交互的接口，用户可以使用这些接口方便的与HDFS进行交互。
   2. NameNode：管理文件系统的命名空间和客户端对文件的访问。
   3. DataNode：负责处理文件系统客户端的读写请求，在名称节点的统一调度下进行数据块的创建、删除、复制等操作。每个数据节点会周期地向名称节点发送“心跳”信息，报告自己的状态，没有按时发送心跳信息的数据节点会被标记为“死机”，不会再给它分配任何I/O请求。
   4. SecondaryNameNode:定期从NameNode中复制元数据并对其合并，生成新的检查点

7. HDFS体系结构的局限性：

   1. 命名空间的限制：名称节点是保存在内存中的，因此名称节点能够容纳对象（文件、块）的个数会受到内存空间大小的限制。
   2. 性能的瓶颈：整个分布式文件系统的吞吐量受限于单个名称节点的吞吐量。
   3. 隔离问题：由于集群中只有一个名称节点，只有一个命名空间，因此无法对不同的应用程序进行隔离。
   4. 集群的可用性：一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用。

8. HDFS副本存储策略：

   两个在同一个机架的不同节点上

   一个在不同机架的节点上

   （1）如果集群内发起写操作请求，将第一个副本放置在发起写操作请求的数据节点上，实现就近写入数据。如果是在集群外发起写操作请求，则从集群内部挑选一台磁盘空间较为充足、CPU不太忙的数据节点，作为第一个副本的存放地

   （2）第二个副本会被放置在与第一个副本不同的机架的数据节点上。

   （3）第三个副本会被放置在与第一个副本相同的机架的其它节点上。

   （4）如果还有更多副本，随机存放。

8. HDFS块的划分：

   HDFS块默认大小为128MB，默认保存3份。
   1.x版本中为64MB

9. Hbase概念：
   hbase是一个提供高可靠性，高性能，可伸缩，实时读写，分布式的列式数据库，一般采用HDFS作为其底层数据存储系统

10. HBASE主要功能组件：

    1. 库函数：链接到每个客户端
    2. 一个Master主服务器：负责管理和维护HBase表的分区信息，比如一个表被分成了哪些region，每个region存放在哪台region服务器上，同时维护Region服务器列表。因此Master主服务器死机，整个系统都会无效。Master会实时监测集群中的region服务器，把特定的region分配到可用的region服务器上，并保证集群内部不同region服务器之间的负载均衡。当某个region服务器出现故障而失效时，Master会把该故障服务器上存储的region重新分配给其它可用的region服务器。除此之外，Master还处理模式变化，如表和列族的创建。
    3. 许多Region服务器：Region服务器负责存储和维护分配给自己的Region，处理来自客户端的读写请求。

11.  HBase中获取region存储位置信息流程：

    客户端三级寻址

    1.客户端访问ZooKeeper 获取 -ROOT-表的位置信息

    2.访问 -ROOT- 表获取.META.表的信息

    3.访问 .META. 表，找到所需的Region位于哪个Region服务器

    最后 到该Region服务器中读取数据。

    查询过的位置信息会被缓存起来，以后访问时会直接从客户端缓存中获取Region位置信息。直到Region位置失效——即访问时发现位置信息不存在时，再次进行三级寻址。

12. 描述 HBase 中一个 cell 的结构？

    在HBase中，数据存储在以行为单位的表（Table）中。每一行由一个行键（Row Key）唯一标识，并且被划分成若干个列族（Column Family），每个列族包含多列（Column）。HBase中一个Cell（单元格）可以描述为：行键 + 列族 + 列名（Qualifier） + 时间戳 + 值（Value）

13. Mapreduce定义：见上方概念

14. Mapreduce体系架构：
    ![](https://unis-0328-markdown.oss-cn-hangzhou.aliyuncs.com/typora_screenshot/20231231160127.png)

    Client:

    - 通过Client可以提交用户编写的应用程序，用户通过它将应用程序提交到JobTracker端
    - 通过Client提供的一些接口查看当前提交作业的运行状态。

    JobTracker：

    - 负责资源监控和作业调度
    - 监控底层的其它TaskTracker以及当前运行Job的健康状况
    - 一旦探测到失败的情况就把这个任务转移到其它节点继续执行。
    - 跟踪任务执行进度和资源使用量。

    TaskTracker：

    - 接收JobTracker发送的命令，执行具体的任务
    - 把自己的资源使用情况，任务运行进度通过心跳的方式发送给JobTracker

    TaskScheduler：

    - 负责具体分配任务。

    Task：

    - Task分别为Map Task和Reduce Task两种，均由TaskTracker启动

15. Mapreduce键值对归并、合并的不同：
    合并：将具有相同key的<key,value>加起来。比如<a,1>,<a,1>合并为<a,2>

    归并：将具有相同key的键值对归并为一个新的键值对，如<a,1>,<a,2>,<a,1>归并为<a,<1,2,1>>

16. Hive概念：
    hive是一个基于Hadoop的数据仓库工具，可以对存储在Hadoop文件中的数据集进行数据整理，特殊查询和分析处理

17. 数据仓库的体系结构：

    1. 数据源：数据仓库的数据来源。
    2. 数据存储和管理：主要涉及对数据的存储和管理。
    3. 数据服务：为前端工具和应用提供数据服务。
    4. 数据应用：直接面向最终用户。

18. Hive系统架构：

    1. 用户接口模块：用来实现外部应用对Hive的访问。
    2. 驱动模块：包括编译器，优化器，执行器等。所采用的执行引擎可以为Mapreduce、Spark等。
    3. 元数据存储模块：是一个独立的关系数据库，通常是与Mysql数据库连接后创建的一个mysql实例，也可以是hive自带的derby数据库实例。

19. Hive元数据：
    Hive元数据存储模块中主要保存表模式和其它系统的元数据，如表的名称，表的列及其属性，表的分区及其属性，表中数据所在位置信息等。

20. ZooKeeper概念：
    ZooKeeper是根据谷歌Chubby的一个开源实现，是高效可靠的协同工作系统，提供分布式锁之类的基本服务（如统一命名服务、状态同步服务、集群管理、分布式应用配置项管理等），用于构建分布式应用，减轻分布式应用程序所承担的协调任务。

21. 流数据概念、特征：

    概念：流数据，即数据以大量、快速、时变的流形式持续到达。
    特征：

    - 数据快速持续到达，潜在数据量也许是无穷无尽的。
    - 数据来源众多，格式复杂。
    - 数据量大，但是不十分关注存储。一旦流数据中的某个元素经过处理要么被丢弃，要么被归档存储。
    - 注重数据的整体价值，不过分关注个别数据。
    - 数据顺序颠倒，或者不完整。系统无法控制将要处理的新到达的数据元素的顺序。

20. 流计算的概念：

    概念：流计算平台实时获取来自不同数据源的海量数据，经过实时分析处理，获取有价值的信息。
    数据采集——实时分析处理——结果反馈



#### 期中题目补充：

1. 现需要在HDFS的根路径下创建2个文件夹：test1和test2，然后将本地文件“/tmp/testfile.txt”上传到test2中，再把该文件拷贝到test1中，所需执行的命令如下所示。

   hdfs fs mkdir /test1

   hdfs fs mkdir /test2

   hadoop dfs get /tmp/testfile.txt /test2

   hadoop dfs scp /test2/testfile.txt /test1

   上述指令有错误，请指出错误，在下面空白处写出正确的完整的命令。

   应该是笔误？所有命令前必须加- 否则无法识别命令

   hadoop dfs -put /tmp/testfile.txt /test2

   hadoop dfs -cp /test2/testfile.txt /test1

2. Hadoop2.x伪分布式集群配置了一台master主机（管理节点）和两台slave主机（数据节点），集群启动后master主机（管理节点）上运行着NameNode、SecondaryNameNode、DataNode、ResourceManager、NodeManager进程。请问上述论述是否正确，请说明理由，写出各进程的功能？

   不正确，Master应该有NameNode，SecondaryNameNode和ResourceManager

   Slave上应该有DataNode 和 NodeManager

   NameNode：负责管理HDFS（Hadoop Distributed File System）的命名空间，即管理文件和目录的元数据信息。它会记录每个文件的块数、块所在的DataNode、副本数量等信息。

    

   SecondaryNameNode：定期合并fsimage和edits文件，以生成新的fsimage文件。它的作用是辅助NameNode处理元数据，防止元数据丢失。

    

   DataNode：负责存储HDFS中的实际数据块。它会周期性地向NameNode汇报心跳、存储容量等信息。

    

   ResourceManager：负责整个集群的资源管理和作业调度。它会接收来自客户端的请求，分配适当的资源给相应的作业，并监控作业的运行情况。

    

   NodeManager：负责单个节点上的资源管理和作业执行。它会启动和监控容器（Container）来运行作业，并向ResourceManager报告容器的状态。

3. 描述安装配置一个 hadoop 集群的步骤

   1.解压hadoop

   2.配置环境变量

   3.配置主机名映射

   4.配置免密登录

   5.编辑hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml slaves

   6.格式化hdfs

   7.启动hadoop集群

   8.验证集群状态

#### 操作题：

1. 环境变量配置：

   编辑 /etc/profile ——使用vi/vim
   例子：

   添加 export HADOOP_HOME=/路径/hadoop-2.7.6

   ​		 export PATH=$HADOOP_HOME/sbin:\$HADOOP_HOME/bin:\$PATH

2. 关闭防火墙、关闭防火墙自启动
   centos8：
   systemctl stop firewalld.service

   systemctl disable firewalld.service

   centos7:

   systemctl stop firewalld

   systemctl disable firewalld

   centos6:

   service iptables stop

   chkconfig iptables off

3. 网络重启
   centos8:
   service network restart

   centos7:

   systemctl restart network

   centos6:

   service network restart

4. Hadoop启动

   初始化Namenode（如果没有初始化）   ./bin/hdfsnamenode -format 

   ./sbin/start-dfs.sh和./sbin/start-yarn.sh    或者    ./sbin/start-all.sh

5. 网络配置（静态ip配置）

   vi /etc/sysconfig/network-scripts/ifcfg-ens33

   BOOTPROTO=static

   ONBOOT=yes

   \#IP地址

   IPADDR=192.168.XXX.120

   NETMASK=255.255.255.0

   \#网关

   GATEWAY=192.168.XXX.2

   DNS1=114.114.114.114或者与网关地址相同

6. Mapreduce处理逻辑理解

   Map、Reduce、Shuffle

7. HDFS基本操作：

   创建文件夹：hdfs dfs -mkdir /路径

   删除文件夹：hdfs dfs -rm -r /路径

   删除文件: hdfs dfs -rm /文件路径

   上传文件：hdfs dfs -put /本地文件路径 /hdfs路径

   下载文件：hdfs dfs -get /hdfs路径 /本地路径

   显示路径内容:hdfs dfs -ls /路径

8. HIVE操作：

   创建表、创建数据库、删除数据库等

   建表

   create table student(

   id bigint,

   age int,

   name string

   )row format delimited fields terminated by "," #设置分隔符为","

   导入数据：load data local(导入本地数据加上local) inpath "数据地址" into table 表名；







